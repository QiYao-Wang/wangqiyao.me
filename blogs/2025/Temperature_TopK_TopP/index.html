<!DOCTYPE html>
<html lang="en" class="no-js">
  
<head>
  <style>
    :root {
      --primary-color: #2c3e50;
      --secondary-color: #3498db;
      --accent-color: #e74c3c;
      --light-gray: #ecf0f1;
      --dark-gray: #7f8c8d;
      --text-color: #333;
      --sidebar-width: 280px;
      --content-width: 1200px;
    }

    body {
      font-family: 'Helvetica Neue', Arial, sans-serif;
      line-height: 1.6;
      color: var(--text-color);
      max-width: var(--content-width);
      margin: 0 auto;
      padding: 0 20px;
      background-color: #f9f9f9;
    }

    a {
      color: var(--secondary-color);
      text-decoration: none;
      transition: color 0.3s;
    }

    a:hover {
      color: var(--accent-color);
      text-decoration: underline;
    }

    h1, h2, h3, h4, h5 {
      color: var(--primary-color);
      margin-top: 1.5em;
    }

    h1 { 
      font-size: 2.2em;
      margin-top: 0.8em;
      margin-bottom: 0.5em;
      border-bottom: 2px solid var(--light-gray);
      padding-bottom: 0.3em;
    }
    
    h2 { 
      font-size: 1.8em; 
      border-bottom: 1px solid var(--light-gray); 
      padding-bottom: 0.3em; 
      margin-top: 1.8em;
    }
    
    h3 { 
      font-size: 1.5em;
      margin-top: 1.5em;
    }

    /* å¯¼èˆªæ æ ·å¼ */
    .nav {
      display: flex;
      justify-content: flex-end;
      background-color: var(--primary-color);
      padding: 1em;
      border-radius: 5px;
      margin-bottom: 2em;
      box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }

    .nav a {
      color: white;
      margin: 0 1em;
      font-weight: 500;
      padding: 0.5em 0;
      transition: all 0.3s;
    }

    .nav a:hover {
      color: var(--accent-color);
      text-decoration: none;
    }

    /* ä¸»è¦å†…å®¹å¸ƒå±€ */
    .main-content {
      display: flex;
      gap: 2em;
    }

    .content {
      flex: 1;
      min-width: 0;
      background: white;
      padding: 2em;
      border-radius: 5px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.05);
    }

    /* ä¾§è¾¹æ æ ·å¼ */
    .sidebar {
      position: sticky;
      top: 20px;
      width: var(--sidebar-width);
      padding: 1.5em;
      border-radius: 10px;
      margin-bottom: 2em;
      background: white;
      box-shadow: 0 2px 10px rgba(0,0,0,0.05);
      height: fit-content;
      max-height: calc(100vh - 40px);
      overflow-y: auto;
    }

    .sidebar strong {
      display: block;
      font-size: 1.1em;
      color: var(--primary-color);
      padding-bottom: 0.8em;
      margin-bottom: 0.8em;
      border-bottom: 2px solid var(--secondary-color);
    }

    .sidebar ul {
      list-style-type: none;
      padding-left: 0;
      margin: 0;
    }

    .sidebar li {
      margin-bottom: 0.6em;
      position: relative;
      padding-left: 1em;
      transition: all 0.2s ease;
    }

    .sidebar li:before {
      content: "";
      position: absolute;
      left: 0;
      top: 0.6em;
      width: 6px;
      height: 6px;
      background-color: var(--secondary-color);
      border-radius: 50%;
      transition: all 0.2s ease;
    }

    .sidebar li:hover:before {
      background-color: var(--accent-color);
      transform: scale(1.3);
    }

    .sidebar a {
      color: var(--primary-color);
      display: block;
      padding: 0.3em 0;
      transition: all 0.2s ease;
      font-weight: 500;
    }

    .sidebar a:hover {
      color: var(--accent-color);
      padding-left: 5px;
    }

    /* åšå®¢ç‰¹å®šæ ·å¼ */
    .blog-meta {
      color: var(--dark-gray);
      font-size: 0.9em;
      margin-bottom: 1.5em;
      display: flex;
      align-items: center;
    }

    .blog-tag {
      background-color: var(--light-gray);
      color: var(--primary-color);
      padding: 0.2em 0.6em;
      border-radius: 3px;
      font-size: 0.8em;
      margin-left: 0.8em;
    }

    .blog-content {
      margin-top: 1.5em;
    }

    .blog-content p {
      margin-bottom: 1.2em;
    }

    pre {
      background-color: #f5f5f5;
      padding: 1em;
      border-radius: 5px;
      overflow-x: auto;
      margin: 1.5em 0;
      border-left: 4px solid var(--secondary-color);
    }

    code {
      font-family: 'Courier New', Courier, monospace;
      background-color: #f5f5f5;
      padding: 0.2em 0.4em;
      border-radius: 3px;
      font-size: 0.9em;
    }

    figure {
      margin: 1.5em 0;
      text-align: center;
    }

    figure img {
      max-width: 100%;
      border-radius: 5px;
      box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }

    figcaption {
      color: var(--dark-gray);
      font-size: 0.9em;
      margin-top: 0.5em;
    }

    blockquote {
      border-left: 4px solid var(--secondary-color);
      padding-left: 1em;
      margin: 1.5em 0;
      color: var(--dark-gray);
      font-style: italic;
    }

    /* æ•°å­¦å…¬å¼æ ·å¼ */
    .math {
      overflow-x: auto;
      margin: 1em 0;
    }

    /* å“åº”å¼è®¾è®¡ */
    @media (max-width: 900px) {
      .main-content {
        flex-direction: column;
      }
      
      .sidebar {
        position: relative;
        width: auto;
        top: auto;
      }
      
      .nav {
        justify-content: center;
      }
      
      .nav a {
        margin: 0 0.8em;
      }
    }
  </style>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script>hljs.highlightAll();</script>
  <script>
    html {
      scroll-behavior: smooth;
    }
  </script>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
  
  <!-- ä¿®æ”¹MathJaxé…ç½®ä»¥æ”¯æŒè¡Œå†…å…¬å¼ -->
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],  // å¯ç”¨è¡Œå†…æ•°å­¦å…¬å¼
        displayMath: [['$$', '$$'], ['\\[', '\\]']] // æ˜¾ç¤ºæ•°å­¦å…¬å¼
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  
  <script>hljs.highlightAll();</script>
  <script>
    html {
      scroll-behavior: smooth;
    }
  </script>
  
</head>

<body>
  <div class="nav">
    <a href="https://wangqiyao.me/">Homepage</a>
    <a href="https://wangqiyao.me/blogs/">Blogs</a>
  </div>

  <div class="main-content">
    <div class="sidebar sticky">
      <div id="toc">
        <strong>Table of Contents</strong>
        <ul></ul>
      </div>
    </div>
    
    <div class="content">
      <h1 id="Temperature_TopK_TopP">Three Sampling Methods: Temperature, Top K and Top P</h1>
      <div class="blog-meta">
        <span>Feb. 27, 2025 Â· Qiyao Wang</span>
        <span class="blog-tag">#Decoding</span>
      </div>

      <div class="blog-content">
        <h2 id="temperature-sampling">Temperature Sampling</h2>
        <p>é€šè¿‡è°ƒæ•´ temperature èƒ½å¤Ÿæ”¹å˜é€‰æ‹©æŸäº› token çš„æ¦‚ç‡åˆ†å¸ƒï¼Œæ”¾å¤§æˆ–å‡å°‘å…¶ä¸­çš„é‡‡æ ·çš„éšæœºæ€§ã€‚ä¸€èˆ¬å…¶å–å€¼èŒƒå›´åœ¨ [0, +âˆ] ä¹‹é—´ï¼Œå½“æ¸©åº¦æ¥è¿‘ 1 æ—¶ï¼Œä¿ç•™åŸå§‹çš„é‡‡æ ·åˆ†å¸ƒï¼›å½“æ¸©åº¦æ¥è¿‘ 0 æ—¶ï¼Œä¼šé€æ¸å˜æˆå•å³°åˆ†å¸ƒï¼Œå³ä¸ Greedy Search ç±»ä¼¼ï¼›è€Œå½“æ¸©åº¦è¶Šå¤§ï¼Œå¦‚ $>1$ï¼Œæç«¯æƒ…å†µè¶‹äº âˆ æ—¶ï¼Œé‡‡æ ·åˆ†å¸ƒä¼šé€æ¸è¶‹äºå‡åŒ€åˆ†å¸ƒã€‚</p>
        <p>å¯¹äºåºåˆ— $\mathbf(x)=(x_1,x_2,...,x_m)$ï¼Œåˆ©ç”¨æ¸©åº¦å‚æ•° $T$ è¿›è¡Œæ”¾ç¼© $\frac{x_i}{T}$ï¼Œä¹‹åè¿›è¡Œ Softmax è®¡ç®—</p>
        <div class="math">
          $$p(x_i)=\frac{e^{\frac{x_i}{T}}}{\sum_j e^{\frac{x_j}{T}}}$$
        </div>
        <p>ä¿®æ”¹åŸºç±» Sampler ä¸­å‡½æ•°</p>
<pre>
<code class="language-python">def get_next_token_prob_logits(self, input_ids:torch.Tensor):
    # ç¦æ­¢è®¡ç®—å›¾ä¸­æ¢¯åº¦çš„è®¡ç®—
    with torch.no_grad():
    logits = self.model(input_ids=input_ids).logits
    # åœ¨æ­¤ä¹‹å‰ï¼Œlogits å½¢çŠ¶ä¸º torch.Size([1, 1, 151936])
    # è·å¾— Tensor çš„æœ€åä¸€ç»´åº¦ torch.Size([151936])
    logits = logits[0, -1, :]
    probs = torch.softmax(logits, dim=-1)
    return probs, logits</code>
</pre>
        <p>Temperatureçš„ç›¸å…³ä»£ç å’Œäº‹ä¾‹</p>
<pre>
<code class="language-python">class RandomTempSampler(Sampler):
    def __call__(self, prompt, max_new_tokens=10, temp: float=0.5):
        predictions = []
        result = prompt
        # generate until max_len
        for i in range(max_new_tokens):
            input_ids = self.encode(result)
            next_token_logits = self.get_next_token_prob_logits(input_ids)[1]
            next_token_logits /= temp
            probs = torch.softmax(next_token_logits, dim=-1)
            # æ ¹æ®æ¦‚ç‡åˆ†å¸ƒéšæœºé‡‡æ ·
            ids = torch.multinomial(probs, num_samples=1).item()
            result += self.decode(ids)
            predictions.append(probs[ids].item)
        return result

    def sample_plot(self, prompt, temp: float=0.5):
        input_ids = self.encode(prompt)

        nex_token_probs = self.get_next_token_prob_logits(input_ids)[1]
        nex_token_probs /= temp
        probs = torch.softmax(nex_token_probs, dim=-1)

        self.plot_scores(probs, title=f"Temperature: {temp}", k=10)</code>
</pre>
        <p>å¯¹äº "the color of sky is" è¿›è¡Œä¸åŒæ¸©åº¦çš„é‡‡æ ·ï¼Œå¦‚ä¸‹é¢ä¸‰å¹…å›¾æ‰€ç¤ºï¼Œå¯ä»¥çœ‹åˆ°ï¼Œéšç€ temperature çš„å˜å¤§ï¼Œåˆ†å¸ƒé€æ¸å‡åŒ€ã€‚</p>
        <figure>
          <img src="/blogs/2025/Temperature_TopK_TopP/temp-0.1.png" alt="probs">
          <figcaption>å›¾1ï¼šTemperature 0.1ï¼Œç»“æœä¸º 'The color of sky is blue. The color of the sky is a ( ) of the color of the'</figcaption>
        </figure>

        <figure>
          <img src="/blogs/2025/Temperature_TopK_TopP/temp-0.9.png" alt="probs">
          <figcaption>å›¾2ï¼šTemperature 0.9ï¼Œç»“æœä¸º 'The color of sky is dark gray, whose density is a positive integer. Now, choose a random sample'</figcaption>
        </figure>

        <figure>
          <img src="/blogs/2025/Temperature_TopK_TopP/temp-100.png" alt="probs">
          <figcaption>å›¾3ï¼šTemperature 100ï¼Œç»“æœä¸º (çœŸçš„æ˜¯ä¹±ç ï¼Œéšæœºæ€§å¤ªå¤§äº†) 'The color of sky is ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºğ—±Lights\'].\'" @[coverslandÄ±rÄ±leraseâ›·è¶•ğŸ containing BecStrokeGU'ï¼Œå‡ ä¹å·²ç»ä¸ºå‡åŒ€åˆ†å¸ƒ</figcaption>
        </figure>

        <h2 id="top-k-sampling">Top K Sampling</h2>
        <p>Top K é‡‡æ ·åœ¨æ¯ä¸€æ¬¡é€‰æ‹© next token æ—¶ï¼Œåªç¡®ä¿æœ€æœ‰å¯èƒ½çš„ $K$ ä¸ª token èƒ½å¤Ÿè¢«é€‰æ‹©ã€‚å½“ $k=1$ æ—¶ï¼Œé€€åŒ–ä¸º Greedy Searchï¼›å½“ $k=|V|$ æ—¶ï¼Œé€€åŒ–ä¸ºçº¯é‡‡æ ·ã€‚Top K å’Œ Temperature å¯ä»¥ç»“åˆä½¿ç”¨ï¼Œè°ƒæ•´ Top K ä¸­çš„éšæœºæ€§ã€‚</p>
        <p>K çš„ç¡®å®šéœ€è¦ç‰¹åˆ«æ³¨æ„ã€‚K è¾ƒå°æ—¶å¯èƒ½ä¼šå¯¼è‡´æ–‡æœ¬å¤šæ ·æ€§ä¸‹é™ï¼ŒK å¤§æ—¶ä¼šå¯¼è‡´åŒ…å«ä¸åˆé€‚çš„è¯çš„å€™é€‰ã€‚</p>
<pre>
<code class="language-python">class TOPKSampler(Sampler):
    def __call__(self, prompt, max_new_tokens=10, top_k=1, temp: float=0.5):
        predictions = []
        result = prompt
        # generate until max_len
        for i in range(max_new_tokens):
            input_ids = self.encode(result)
            nex_token_logits = self.get_next_token_prob_logits(input_ids)[1]
            nex_token_logits = nex_token_logits / temp
            # ç±»ä¼¼äº maskï¼Œå°†æ¦‚ç‡å°çš„logits æ¢æˆ -inf
            indices_to_remove = nex_token_logits < torch.topk(nex_token_logits,top_k)[0][...,-1, None]
            new_logits = torch.clone(nex_token_logits)
            new_logits[indices_to_remove] = float('-inf')

            probs = torch.softmax(new_logits, dim=-1)
            ids = torch.multinomial(probs, num_samples=1).item()
            result += self.decode(ids)
            predictions.append(probs[ids].item)
        return result

    def sample_plot(self, prompt,top_k=5, temp: float=0.5):
        input_ids = self.encode(prompt)
        next_token_logtis = self.get_next_token_prob_logits(input_ids)[1]
        next_token_logtis = next_token_logtis / temp

        indices_to_remove = next_token_logtis < torch.topk(next_token_logtis,top_k)[0][...,-1, None]
        new_logits = torch.clone(next_token_logtis)
        new_logits[indices_to_remove] = float('-inf')

        probs = torch.softmax(new_logits, dim=-1)
        self.plot_scores(probs, title=f"Temperature: {temp} Top K:{top_k}", k= top_k + int(math.sqrt(top_k)))</code>
</pre>
        <p>å¯¹äº "the color of sky is" è¿›è¡Œå¸¦æœ‰æ¸©åº¦çš„ TopK é‡‡æ ·ï¼Œå…¶ä¸­ $K=10,T=0.5$ æ—¶çš„ç»“æœä¸º "The color of sky is blue. If you want to make the sky appear blue, you can use a certain amount of blue paint. If you want to make the sky appear yellow,"ã€‚</p>
        <p>è°ƒæ•´ä¸åŒçš„æ¸©åº¦ï¼Œå¦‚å›¾4å’Œå›¾5æ‰€ç¤º</p>
        <figure>
          <img src="/blogs/2025/Temperature_TopK_TopP/topk-10-0.1.png" alt="probs">
          <figcaption>å›¾4ï¼šTemperature: 0.1, TopK: 10</figcaption>
        </figure>
        <figure>
          <img src="/blogs/2025/Temperature_TopK_TopP/topk-10-0.9.png" alt="probs">
          <figcaption>å›¾5ï¼šTemperature: 0.9, TopK: 10</figcaption>
        </figure>

        <h2 id="top-p-sampling">Top P Sampling</h2>
        <p>Top P Sampling åˆç§°ä¸ºæ ¸é‡‡æ ·ï¼Œå…¶ä¸ Top K Sampling ç±»ä¼¼ï¼Œé€šè¿‡å¯¹å¯é€‰æ‹©çš„è¯é›†è¿›è¡ŒæŸç§é™åˆ¶ï¼Œæ¥é€‰æ‹©æœ€å°çš„è¯é›†ã€‚Top P Sampling é€šè¿‡é™åˆ¶æœ€å°è¯é›†ä¸­æ‰€æœ‰è¯çš„æ¦‚ç‡å’Œå°äº $p$ æ¥å®ç°åŠ¨æ€è°ƒæ•´å€™é€‰è¯ã€‚</p>
<pre>
<code class="language-python">class NucleusSampler(Sampler):
    def __call__(self, prompt, max_new_tokens=10, p: float=0.7):
        predictions = []
        result = prompt
        # generate until max_len
        for i in range(max_new_tokens):
            input_ids = self.encode(result)
            next_token_logits = self.get_next_token_prob_logits(input_ids)[1]
            sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)
            cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)

            sorted_indices_to_remove = cumulative_probs > p

            # è¿™å¥è¯éœ€è¦æ–Ÿé…Œ
            sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()
            sorted_indices_to_remove[..., 0] = 0

            indices_to_remove = sorted_indices[sorted_indices_to_remove]
            new_logits = torch.clone(next_token_logits)
            new_logits[indices_to_remove] = float('-inf')

            scores = torch.softmax(new_logits, dim=-1)
            ids = torch.multinomial(scores, num_samples=1).item()

            result += self.decode(ids)

            predictions.append(scores[ids].item)

        return result

    def sample_plot(self, prompt,p: float=0.7):
        input_ids = self.encode(prompt)
        next_token_logits = self.get_next_token_prob_logits(input_ids)[1]
        sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)
        cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)

        sorted_indices_to_remove = cumulative_probs > p
        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()
        sorted_indices_to_remove[..., 0] = 0

        indices_to_remove = sorted_indices[sorted_indices_to_remove]
        new_logits = torch.clone(sorted_logits)
        new_logits[indices_to_remove] = float('-inf')

        probs = torch.softmax(new_logits, dim=-1)
        self.plot_scores(probs, title=f"P: {p}", k=10)</code>
</pre>
        <p>å¯¹äº "the color of sky is" åœ¨ $p=0.8$ æ—¶çš„è¾“å‡ºç»“æœä¸º "The color of sky is blue. This belongs to\nA. The subject of cognition\nB. The"</p>
        <p>å…¶ä¸­åœ¨ä¸åŒçš„ $p$ å€¼ä¸‹çš„é‡‡æ ·æƒ…å†µå¦‚å›¾6å’Œå›¾7æ‰€ç¤º</p>
        <figure>
          <img src="/blogs/2025/Temperature_TopK_TopP/topp-0.8.png" alt="probs">
          <figcaption>å›¾6ï¼šP: 0.8</figcaption>
        </figure>
        <figure>
          <img src="/blogs/2025/Temperature_TopK_TopP/topp-0.1.png" alt="probs">
          <figcaption>å›¾7ï¼šP: 0.1</figcaption>
        </figure>

        <h1 id="reference">Reference</h1>

        <h1 id="contact">Contact</h1>
        <p>There may be some errors present. If you find any, please feel free to contact me at <code>wangqiyao@mail.dlut.edu.cn</code>. I would appreciate it!</p>
      </div>
    </div>
  </div>

  <script>
    // åŠ¨æ€ç”Ÿæˆç›®å½•
    const toc = document.getElementById('toc');
    toc.innerHTML = '<strong>Table of Contents</strong>';

    const ul = document.createElement('ul');
    toc.appendChild(ul);

    // è·å–æ‰€æœ‰æ ‡é¢˜
    const headers = document.querySelectorAll('h1, h2, h3, h4, h5, h6');
    headers.forEach(header => {
        // å¿½ç•¥ h1ï¼Œä¸æ·»åŠ åˆ°ç›®å½•ä¸­
        if (header.tagName === 'H1') return;

        const li = document.createElement('li');
        li.style.marginLeft = `${(parseInt(header.tagName[1]) - 1) * 10}px`;

        const a = document.createElement('a');
        a.href = `#${header.id || header.innerText.replace(/\s+/g, '-').toLowerCase()}`;
        a.textContent = header.innerText;
        a.target = "_self";

        // å¦‚æœæ˜¯ h2ï¼Œä½¿ç”¨é»‘è‰²å®å¿ƒç‚¹
        if (header.tagName === 'H2') {
            li.style.listStyleType = 'disc';  // é»‘è‰²å®å¿ƒåœ†ç‚¹
            a.style.color = 'black';  // h2 ä¸ºé»‘è‰²
        }
        // å¦‚æœæ˜¯ h3ï¼Œä½¿ç”¨ç©ºå¿ƒåœ†ç‚¹
        else if (header.tagName === 'H3') {
            li.style.listStyleType = 'circle';  // ç©ºå¿ƒåœ†ç‚¹
            a.style.color = 'gray';  // h3 ä¸ºç°è‰²
        }
        // å¦‚æœæ˜¯ h4ï¼Œä½¿ç”¨æ–¹å—
        else if (header.tagName === 'H4') {
            li.style.listStyleType = 'square';  // æ–¹å—
            a.style.color = 'gray';  // h4 ä¸ºç°è‰²
        }
        // å¦‚æœæ˜¯ h5 å’Œ h6ï¼Œä½¿ç”¨æ–¹å—
        else {
            li.style.listStyleType = 'square';  // æ–¹å—
            a.style.color = 'gray';  // h5 å’Œ h6 ä¸ºç°è‰²
        }

        if (!header.id) {
            header.id = header.innerText.replace(/\s+/g, '-').toLowerCase();
        }

        li.appendChild(a);
        ul.appendChild(li);
    });

    // æ·»åŠ MathJaxç±»å‹æç¤º
    document.addEventListener('DOMContentLoaded', function() {
      if (window.MathJax) {
        MathJax.typesetPromise();
      }
    });
  </script>
</body>
</html>
